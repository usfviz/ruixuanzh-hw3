barplot(x1,col = "yellow4")
barplot(x1,colors()[103])
barplot(x1,col = colors()[103])
library("colorspace", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
palette()
?palette
install.packages("RColorBrewer")
library("RColorBrewer", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
help(package="RColorBrewer")
display.brewer.all()
display.brewer.pal(11,set3)
display.brewer.pal(11,Set3)
display.brewer.pal(11, Set3)
display.brewer.pal(11, "Set3")
mixed <- brewer.pal(11,"Set3")
barplot(x1, col=mixed)
rm(ls=objects())
rm(list=objects())
rm(list=ls())
rm(list=objects())
x1 <- c(rep(10,5))
barplot(x1, col = rainbow(5))
colors()
palette()
barplot(x1, col = red(5))
rm(list=ls())
require("datasets")
?chickwts
str(chickwts)
data("chickwts")
data(chickwts)
data(chickwts)
chickwts
rm(list=ls())
require("datasets")
data(chickwts)
chickwts
View(chickwts)
barplot(chickwts)
plot(chickwts$feed)
barplot(chickwts$feed)
feed <- table(chickwts$feed)
barplot(feed)
barplot(feed)
barplot(feed)
plot(chickwts)
plot(chickwts$weight)
barplot(chickwts$feed)
plot(chickwts$feed)
barplot(feed[order(feed,decreasing=TRUE)])
rm(list=ls())
x1= c(rep("red",3365)
rep("green",789)
rep("pink",909)
rep("black",7987))
x1= c(rep("red",3365),
rep("green",789),
rep("pink",909),
rep("black",7987))
x2 <- table(x1)
x2
barplot(x2)
barplot(x2[order(decreasing = TRUE)])
x3 <- sort(x2)
x3
x3 <- sort(x2,decreasing = TRUE)
x3
prop.table(x3)
round(prop.table(x3),2)
cars
str(cars)
summary(cars)
data(cars)
cars
boxplot(cars$dist)
install.packages("psych")
library(psych)
describe(cars)
prop.test(98,162)
prop.test(98,162,alternative = "greater",conf.level = 0.9)
rm(list=ls())
rm(list = ls())
source('~/.active-rstudio-document', echo=TRUE)
```{r,echo=FALSE}
library(glmnet) ##generalized linear model via penalized maximum likelihood, i.e.ridge & lasso
library(leaps) ##subset selection, AIC BIC
library(pls) ## PLS, PCA
library(ggplot2)
#generate data
gendata_prob1=function(){
n = 1000; p = 3
x1 = rnorm(n); x2 = rnorm(n);
e = rnorm(n); epsilon = rnorm(n);
x3 = 2/3 * x1 + 2/3 * x2 + 1/3 * e
X = cbind(x1, x2, x3)
colnames(X)=c('X1', 'X2', 'X3')
beta = c(2, 3)
y = beta[1] * x1 + beta[2] * x2 + epsilon
return(list(X=X, y=y))
}
myData = gendata_prob1();
```
## Problem 1
### 1.1   Use AIC to select the best sub-model. Does it select the correct model?
```{r,echo=FALSE}
# regsubsets returns values
# including model selection results(outmat), RSS, adjusted R square, Mallow's Cp, BIC,
RSSleaps=regsubsets(myData$X, myData$y)
sumleaps = summary(RSSleaps)
sumleaps
# Calculate the AIC/BIC/
lmfit = lm(myData$y ~ myData$X)
msize=apply(sumleaps$which,1,sum);
n=dim(myData$X)[1];
AIC = n*log(sumleaps$rss/n) + 2*msize;
BIC = n*log(sumleaps$rss/n) + msize*log(n);
print(AIC)
```
Model 2 has the smalllest AIC, with AIC=59.43703. So AIC selected model 2, which has X1 and X2 as predictor. As it turns out, model 2 is the correct model.
### 1.2   Use BIC to select the best sub-model. Does it select the correct model?
```{r}
sumleaps
names(sumleaps)
sumleaps$bic
```
Model 2 has the smalllest BIC, with BIC=-2537.931. So according to BIC, we should select model 2, which has X1 and X2 as predictor. As it turns out, model 2 is the correct model.
```{r}
print(BIC)
```
Note, here we use two ways to obatin BIC. The first way is caculate BIC through BIC = n*log(sumleaps$rss/n) + msize*log(n), the other one is use the BIC obtained from leaps. The values are different but the only difference is the constant. All indicates model 2 is the BIC's choice.
### 1.3    Try Lasso with lambda.min and lambda.1se. Which procedure would select the correct model?
```{r, echo=FALSE}
ntest = round(n*0.2)
ntrain = n-ntest;
test.id = sample(1:n, ntest);
Ytest = myData$y[test.id];
cv.out = cv.glmnet(myData$X[-test.id,], myData$y[-test.id], alpha=1)
lambda.min= cv.out$lambda.min
mylasso.min.coef = predict(cv.out, s=lambda.min, type="coefficients")
mylasso.min.coef
mylasso.1se.coef = predict(cv.out, s=cv.out$lambda.1se, type="coefficients")
mylasso.1se.coef
```
### 1.4    Produce a path plot for Lasso. Based on the path plot, explain why it is impossible
for Lasso to select the correct model.
```{r, echo=FALSE}
mylasso = glmnet(myData$X, myData$y, alpha=1)
plot(mylasso, label=TRUE)
```
require(randomForest)
require(MASS)
set.seed(101)
dim(Boston)
train=sample(1:nrow(Boston),300)
?Boston
rf.boston=randomForest(medv~.data=Boston,subset=train)
rf.boston=randomForest(medv~.,data=Boston,subset=train)
rf.boston
oob.err=double(13)
test.err=double(13)
for(mtry in 1:13){
fit=randomForest(medv~., data=Boston, subset = train, mtry=mtry, ntree=400)
oob.err[mtry]=fit$mse[400]
}
oob.err[mtry]
fit
fit$mse
fit$mse[400]
?step
#read data
install.packages("data.table")
library(data.table)
require(bit64)
train<-fread("/Users/Ruixuan/Documents/542/Project/train.csv",header = TRUE,sep = ',') # check wether dimentions of the data frame is correct
View(train)
head(train)
source('~/Documents/542/Project/kaggle.example.R', echo=TRUE)
library(data.table)
library(bit64)
library(R.utils)
train<-fread("/Users/Ruixuan/Documents/542/Project/train.csv",header = TRUE,sep = ',') # check wether dimentions of the data frame is correct
test<-fread("/Users/Ruixuan/Documents/542/Project/test.csv",header = TRUE,sep = ',') # check wether dimentions of the data frame is correct
y = train$target
# remove the id and target
train = subset(train, select=-c(ID, target))
# get the rowcount
row_count = countLines("/Users/Ruixuan/Documents/542/Project/train.csv")
cat("Row count : ", row_count[1], "; Predictor column count : ", ncol(train))
# The proportion of NA values
(sum(is.na(train)))/(ncol(train)*nrow(train))
# check the dupicate rows
sum(duplicated(train)) # nrow(train) - nrow(unique(train))
col_ct = sapply(train, function(x) length(unique(x)))
cat("Constant feature count:", length(col_ct[col_ct==1]))
# we can just remove these columns
trainID = train[, which(!(names(train) %in% names(col_ct[col_ct==1]))), with=FALSE]
length(unique(x))
length(unique(train))
col_ct
col_ct[col_cy==1]
col_ct[col_ct==1]
VAR_0207$trainID
VAR_0208$trainID
View(trainID)
VAR_0210$trainID
trainID$VAR_00208
trainID$VAR_00209
trainID$VAR_0209
trainID$VAR_0208
View(trainID)
str(trainID)
names(trainID)
cat("Constant feature :", col_ct[col_ct==1])
cat("Constant feature count:", length(col_ct[col_ct==1]))
cat("Constant feature :", col_ct[col_ct==1])
col_ct[col_ct==1
col_ct[col_ct==1]
col_ct[col_ct==1]
head(trainID)
col_ct[col_ct==1]
cat("Constant feature :", col_ct[col_ct==1])
cat("Constant feature :", )
cat("Constant feature :" )
col_ct[col_ct==1]
trainID$VAR_0840
sapply(train,is.numeric)
train_numr = trainShort[, sapply(train, is.numeric)]
trainShort = train[, which(!(names(train) %in% names(col_ct[col_ct==1]))), with=FALSE]
train_numr = trainShort[, sapply(train, is.numeric)]
train_numr
sapply(train,is.numeric)
dim(sapply(train,is.numeric))
a<-sapply(train,is.numeric)
a
str(a)
dim(a)
train_char = train[, sapply(train, is.character)]
cat("Numerical column count : ", dim(train_numr)[2],
"; Character column count : ", dim(train_char)[2])
train_numr
dim(train_numr)
train_numr = trainShort[, which(sapply(train, is.numeric)),with=FALSE]
train_numr = trainShort[, sapply(train, is.numeric),with=FALSE]
sum(sapply(train,is.numeric))
sum(sapply(trainShort,is.numeric))
sum(sapply(trainShort,is.character))
train<-trainShort
train_numr = sum(sapply(train, is.numeric))
train_numr = sum(sapply(train, is.numeric))
train_char = sum(sapply(train, is.character)
cat("Numerical column count : ", train_numr,
train_char = sum(sapply(train, is.character))
cat("Numerical column count : ", train_numr,
"; Character column count : ", train_char)
str(lapply(train_char, unique), vec.len = 4)
train<-as.data.frame(trainShort)
train_numr = train[, sapply(train, is.numeric)]
train_char = train[, sapply(train, is.character)]
cat("Numerical column count : ", dim(train_numr)[2],
"; Character column count : ", dim(train_char)[2])
str(lapply(train_char, unique), vec.len = 4)
train$VAR_0217
str(lapply(train_char, unique), vec.len = 4)
train$VAR_0044
str(lapply(train_numr, unique), vec.len = 4)
describe(lapply(train_numr, unique), vec.len = 4)
summary(lapply(train_numr,unique),vec.len = 4)
?write.table
#read data
library(data.table)
library(bit64)
library(R.utils)
train<-fread("/Users/Ruixuan/Documents/542/Project/train.csv",header = TRUE,sep = ',')
test<-fread("/Users/Ruixuan/Documents/542/Project/test.csv",header = TRUE,sep = ',')
y = train$target
# remove the id and target
train = subset(train, select=-c(ID, target))
# get the rowcount
row_count = countLines("/Users/Ruixuan/Documents/542/Project/train.csv")
cat("Row count : ", row_count[1], "; Predictor column count : ", ncol(train))
# The proportion of NA values
(sum(is.na(train)))/(ncol(train)*nrow(train))
# check the dupicate rows
sum(duplicated(train)) # nrow(train) - nrow(unique(train))
col_ct = sapply(train, function(x) length(unique(x)))
cat("Constant feature count:", length(col_ct[col_ct==1]))
cat("Constant feature :" )
col_ct[col_ct==1]
# VAR_0207 VAR_0213 VAR_0840 VAR_0847 VAR_1428
# we can just remove these columns
trainShort = train[, which(!(names(train) %in% names(col_ct[col_ct==1]))), with=FALSE]
# numercial columns/ non numerical columns
train<-as.data.frame(trainShort)
train_numr = train[, sapply(train, is.numeric)]
train_char = train[, sapply(train, is.character)]
cat("Numerical column count : ", dim(train_numr)[2],
"; Character column count : ", dim(train_char)[2])
# look into the non numerical features.
str(lapply(train_char, unique), vec.len = 4)
train_date = train_char[,grep("JAN1|FEB1|MAR1", train_char),]
View(train_date)
View(train_date)
complete.cases(train)
library(data.table)
library(bit64)
library(R.utils)
train<-fread("/Users/Ruixuan/Documents/542/Project/train.csv",header = TRUE,sep = ',')
train0<-na.omit(train)
pMissing <- function(x){sum(is.na(x))/length(x)*100}
colmiss<-as.vector(apply(train,2,pMissing))
colmiss>50
train1 = subset(train,select=which(colmiss==FALSE))
train1<-na.omit(train1)
any(is.na(train1))
colmiss
rowmiss<-as.vector(apply(train1,1,pMissing))
rowmiss>50
sum(rowmiss>50)
View(train1)
sum(colmiss<50)
sum(colmiss>50)
summary(colmiss)
dim(colmiss)
pMissing <- function(x){sum(is.na(x))/length(x)*100}
colmiss<-as.vector(apply(train,2,pMissing))
dim(colmiss)
summary(colmiss)
colmiss>50
sum(colmiss>50)
train1 = subset(train,which(colmiss<50))
train1 = train[which(colmiss<50)]
any(is.na(train1))
rowmiss<-as.vector(apply(train1,1,pMissing))
rowmiss>50
sum(rowmiss>50)
sum(rowmiss>20)
sum(rowmiss>5)
sum(rowmiss>10)
sum(is.na(train2))
library(xlsx)
library(forecast)
mydata <- read.xlsx("/Users/Ruixuan/Downloads/urb.xlsx",1)
country <- c("Japan", "S.Korea","Germany","UK","France","US", "China", "India", "Brazil")
empty <- matrix(rep(0,90),nrow = 10, ncol = 9)
colname(empty) <- country
colnames(empty) <- country
empty
rownames(empty) <-c(2012,2013,2014,2015,2016,2017,2018,2019,2020,2021)
empty
country[1]
for (i in 1:9){
country[i] <- ts(mydata[,i+1],start=1950, end=2011, frequency = 1)
}
for (i in 1:9){
country[i] <- ts(mydata[,i+1],start=1950, end=2011, frequency = 1)
}
dim(mydata)
country[1] <- ts(mydata[,2], start=1950, end=2011, frequency = 1)
japan <- ts(mydata[,i+1],start=1950, end=2011, frequency = 1)
# function "auto.arima" automatically fits a model.
fit.japan <- auto.arima(japan)
#
Box.japan <- Box.test(fit.japan$residuals, type = "Ljung-Box")
if (Box.japan$p.value > 0.05) {paste("japan", "has past the serial correlation test.")}
# function "forecast.Arima" gives you the forecasted value.
forecast.japan <- forecast.Arima(fit.japan, h=10)
plot.japan <- plot.forecast(forecast.japan)
empty[,1] <- as.vector(forecast.japan$mean)
empty
plot(1:10,1:10)
plot(1:10,1:10)
getwd()
getwd
getwd()
library(ggplot2)
library(gridExtra)
d <- read.csv("fake-tvads-data.csv")
d <- read.csv("fake-tvads-data.csv")
getwd()
getwd()
source("http://www.openintro.org/stat/data/arbuthnot.R")
library(ggplot2)
library(reshape2)
names(arbuthnot) <- c("Year", "Men", "Women")
arbuthnot.melt <- melt(arbuthnot, id.vars = 'Year', variable.name = 'Sex',
value.name = 'Rate')
View(arbuthnot)
View(arbuthnot.melt)
library(ggplot2)
library(gridExtra)
library(reshape2)
# creating a vector of time from 8am to 9am
d <- read.csv("fake-tvads-data.csv")
d$t <- strptime(as.character(d$t), '%Y-%m-%d %H:%M:%S')
# Top Plot Data da 720 observations
da <- subset(d, type=="audience")
da <- droplevels(da) # Removes unneeded types or categories
# Bottom Plot Data d 1440
d <- subset(d, type %in% c("tune_in", "tune_out"))
d <- droplevels(d)
# dataset for pink points
events <- (60/5) * c(10, 20, 25, 35, 40, 47, 53)
red <- da[events,]
xinter <- red$t
# http://docs.ggplot2.org/dev/vignettes/themes.html
# http://colorbrewer2.org/#type=qualitative&scheme=Set1&n=4
# http://sape.inf.usi.ch/quick-reference/ggplot2/colour
### bottom
theme2 <- theme(
axis.text = element_text(size = 10),
axis.text.y=element_blank(),
axis.title=element_blank(),
axis.ticks.y=element_blank(),
legend.background = element_rect(fill = "grey90", color="grey"),
legend.position = c(0.10, 0.70),
legend.title = element_blank(),
legend.key = element_rect(fill = "grey90", colour = "grey90"),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_rect(fill = "white", color = "grey40", size=0.5),
plot.margin=unit(c(0,1,1,1),"cm")
)
pl <- ggplot(d, aes(x=t, y=value, color=type)) + geom_point(size=0.1)
pl <- pl + geom_line(size=0.5)
pl <- pl + geom_vline(xintercept = as.numeric(xinter), color = "grey")
pl <- pl + scale_color_manual(values=c("#4daf4a", "#377eb8"))
pl <- pl + theme2
#### top
theme1 <- theme(
axis.text.y=element_blank(),
axis.text.x=element_blank(),
axis.title=element_blank(),
axis.ticks=element_blank(),
legend.background = element_rect(fill = "grey90", color="grey"),
legend.position = c(0.10, 0.70),
legend.title = element_blank(),
legend.key = element_rect(fill = "grey90", colour = "grey90"),
panel.grid.major = element_line(colour = "grey90", size=0.5, linetype="dashed"),
panel.grid.minor = element_blank(),
panel.background = element_rect(fill = "white", color = "grey40", size=0.5),
plot.margin=unit(c(1,1,-0.1,1),"cm"))
# dataset for geom_segment
sg <- red[, c('t', 'value')]
sg$value2 <- sg$value
names(sg) <- c("t", "circle", "line")
sg.melt <- melt(sg, id.vars = 't', variable.name = 'type', value.name = 'value')
pl1 <- ggplot(da, aes(x=t, y=value)) + geom_point(data = red, colour = "violetred2", shape = 21) + geom_line(size=0.5,colour = "violetred3") + theme1 + labs(x=NULL)
pl1 <- pl1 + geom_segment(data=sg, aes(xend=t, yend=-Inf), colour = "grey")
grid.arrange(pl1, pl, ncol=1, nrow =2, heights = c(0.7, 0.3))
library(ggplot2)
library(gridExtra)
library(reshape2)
# creating a vector of time from 8am to 9am
d <- read.csv("fake-tvads-data.csv")
d$t <- strptime(as.character(d$t), '%Y-%m-%d %H:%M:%S')
# Top Plot Data da 720 observations
da <- subset(d, type=="audience")
da <- droplevels(da) # Removes unneeded types or categories
# Bottom Plot Data d 1440
d <- subset(d, type %in% c("tune_in", "tune_out"))
d <- droplevels(d)
# dataset for pink points
events <- (60/5) * c(10, 20, 25, 35, 40, 47, 53)
red <- da[events,]
xinter <- red$t
# http://docs.ggplot2.org/dev/vignettes/themes.html
# http://colorbrewer2.org/#type=qualitative&scheme=Set1&n=4
# http://sape.inf.usi.ch/quick-reference/ggplot2/colour
### bottom
theme2 <- theme(
axis.text = element_text(size = 10),
axis.text.y=element_blank(),
axis.title=element_blank(),
axis.ticks.y=element_blank(),
legend.background = element_rect(fill = "grey90", color="grey"),
legend.position = c(0.10, 0.70),
legend.title = element_blank(),
legend.key = element_rect(fill = "grey90", colour = "grey90"),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_rect(fill = "white", color = "grey40", size=0.5),
plot.margin=unit(c(0,1,1,1),"cm")
)
pl <- ggplot(d, aes(x=t, y=value, color=type)) + geom_point(size=0.1)
pl <- pl + geom_line(size=0.5)
pl <- pl + geom_vline(xintercept = as.numeric(xinter), color = "grey")
pl <- pl + scale_color_manual(values=c("#4daf4a", "#377eb8"))
pl <- pl + theme2
#### top
theme1 <- theme(
axis.text.y=element_blank(),
axis.text.x=element_blank(),
axis.title=element_blank(),
axis.ticks=element_blank(),
legend.background = element_rect(fill = "grey90", color="grey"),
legend.position = c(0.10, 0.70),
legend.title = element_blank(),
legend.key = element_rect(fill = "grey90", colour = "grey90"),
panel.grid.major = element_line(colour = "grey90", size=0.5, linetype="dashed"),
panel.grid.minor = element_blank(),
panel.background = element_rect(fill = "white", color = "grey40", size=0.5),
plot.margin=unit(c(1,1,-0.1,1),"cm"))
# dataset for geom_segment
sg <- red[, c('t', 'value')]
sg$value2 <- sg$value
names(sg) <- c("t", "circle", "line")
sg.melt <- melt(sg, id.vars = 't', variable.name = 'type', value.name = 'value')
pl1 <- ggplot(da, aes(x=t, y=value)) + geom_point(data = red, colour = "violetred2", shape = 21) + geom_line(size=0.5,colour = "violetred3") + theme1 + labs(x=NULL)
pl1 <- pl1 + geom_segment(data=sg, aes(xend=t, yend=-Inf), colour = "grey")
grid.arrange(pl1, pl, ncol=1, nrow =2, heights = c(0.7, 0.3))
getwd()
getwd()
